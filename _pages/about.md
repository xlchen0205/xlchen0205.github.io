---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- {% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %} -->

<span class='anchor' id='about-me'></span>

Hi there! I am Xinlong Chen (ÈôàÈë´Èæô), a Ph.D. student at [NLPR](http://www.cripac.ia.ac.cn/CN/model/index.htm), [CASIA](https://www.ia.cas.cn/), where I am fortunate to be advised by Prof. [Tieniu Tan](https://scholar.google.com/citations?user=W-FGd_UAAAAJ&hl=en) and co-advised by Prof. [Qiang Liu](https://scholar.google.com/citations?user=D-lKLcMAAAAJ&hl=en). My research focuses on the training and application of MLLMs, with particular interests in video understanding and hallucination mitigation.

Currently, I am a research intern at [Kling Team](https://github.com/KwaiVGI), [Kuaishou Technology](https://www.kuaishou.com/en), under the guidance of [Yuanxing Zhang](https://scholar.google.com/citations?user=COdftTMAAAAJ&hl=en) and [Weihong Lin](https://scholar.google.com/citations?user=Pb9wJ1sAAAAJ&hl=en).

<!-- # üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìù Selected Publications ([Full List](https://scholar.google.com/citations?hl=en&user=5v7aJCIAAAAJ))

## Video Understanding
- **\[Preprint\]** | [AVoCaDO: An Audiovisual Video Captioner Driven by Temporal Orchestration](https://arxiv.org/abs/2510.10395)<br>
**Xinlong Chen**, Yue Ding, Weihong Lin, Jingyun Hua, Linli Yao, Yang Shi, Bozhou Li, Yuanxing Zhang, Qiang Liu, Pengfei Wan, Liang Wang, Tieniu Tan

- **\[Preprint\]** | [VidBridge-R1: Bridging QA and Captioning for RL-based Video Understanding Models with Intermediate Proxy Tasks](https://www.arxiv.org/abs/2506.09079)<br>
**Xinlong Chen**, Yuanxing Zhang, Yushuo Guan, Weihong Lin, Zekun Wang, Bohan Zeng, Yang Shi, Sihan Yang, Qiang Liu, Pengfei Wan, Liang Wang, Tieniu Tan

- **\[Findings of ACL 2025\]** | [VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation](https://arxiv.org/abs/2502.12782)<br>
**Xinlong Chen**, Yuanxing Zhang, Chongling Rao, Yushuo Guan, Jiaheng Liu, Fuzheng Zhang, Chengru Song, Qiang Liu, Di Zhang, Tieniu Tan

## Hallucination Mitigation
- **\[EMNLP 2025\]** | [Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models](https://arxiv.org/abs/2501.09997)<br>
Qiang Liu, **Xinlong Chen**, Yue Ding, Bowen Song, Weiqiang Wang, Shu Wu, Liang Wang

- **\[Findings of ACL 2025\]** | [Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2505.17061)<br>
**Xinlong Chen**, Yuanxing Zhang, Qiang Liu, Junfei Wu, Fuzheng Zhang, Tieniu Tan 

# üìñ Education
- *2025.09 - 2030.06 (expected)*, Ph.D. Student in AI, New Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences
  - Supervisor: Prof. [Tieniu Tan](https://scholar.google.com/citations?user=W-FGd_UAAAAJ&hl=en) and Prof. [Qiang Liu](https://scholar.google.com/citations?user=D-lKLcMAAAAJ&hl=en)
- *2021.09 - 2025.06*, B.Eng. in AI, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology
  - Rank: 1 / 100  \|  Average Grade: 93.67 / 100

<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Internships
- *2024.11 - Present*, [Kling Team](https://github.com/KwaiVGI), [Kuaishou Technology](https://www.kuaishou.com/en)
  - Mentor: [Yuanxing Zhang](https://scholar.google.com/citations?user=COdftTMAAAAJ&hl=en) and [Weihong Lin](https://scholar.google.com/citations?user=Pb9wJ1sAAAAJ&hl=en)
  - Focus: Multimodal understanding

---

<div style="text-align: center;">
<a href="https://clustrmaps.com/site/1c88n" title="ClustrMaps"><img src="//www.clustrmaps.com/map_v2.png?d=3jKzizCpFZ9dw-JS5N6UVVR8gADb5L9LrWx2T29C93E&cl=ffffff"></a>
<div style="margin-top: 5px; font-size: 0.85em; color: #999;">Last updated: October 17, 2025</div>
</div>